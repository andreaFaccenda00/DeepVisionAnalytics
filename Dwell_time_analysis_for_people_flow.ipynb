{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te48PpbpN7P2"
      },
      "source": [
        "# YOLOv8 Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yv9_yvRi4Rf",
        "outputId": "4317054b-9377-40b4-e98c-11cb5d0b6a99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "\n",
        "folder_url = 'https://drive.google.com/drive/folders/1Dc0W67KQAJ34QCSI_PaZYqPFu1V1651_?usp=sharing'\n",
        "\n",
        "!pip install --upgrade gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "folder_id = '1Dc0W67KQAJ34QCSI_PaZYqPFu1V1651_'\n",
        "\n",
        "\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", quiet=False, use_cookies=False)\n",
        "\n",
        "print(\"File nella cartella scaricata:\")\n",
        "print(os.listdir('models'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsU-y6yTj3Bu",
        "outputId": "497fb7af-08b1-4b8d-81c3-39b7c27758ba"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "\n",
        "folder_url = 'https://drive.google.com/drive/folders/1Vz2TCsDS_bbENCkWykH5Mz1T0OxpSrks?usp=sharing'\n",
        "\n",
        "import gdown\n",
        "\n",
        "folder_id = '1Vz2TCsDS_bbENCkWykH5Mz1T0OxpSrks'\n",
        "\n",
        "\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", quiet=False, use_cookies=False)\n",
        "\n",
        "print(\"File nella cartella scaricata:\")\n",
        "print(os.listdir('data'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4ePFsSLZx-",
        "outputId": "0e9daf9d-22ac-4903-e104-87b34989a728"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install inference==0.9.17\n",
        "!pip install supervision>=0.20.0\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAzz_fL1a0wS"
      },
      "source": [
        "# YOLOv8 Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qioQslCGa7md"
      },
      "outputs": [],
      "source": [
        "# Download the YOLOv8 Architecture File\n",
        "!wget https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/models/v8/yolov8.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLOKecoBbCQj"
      },
      "source": [
        "## Modified YOLOv8 Architecture for Small Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJgv81uEbCCC"
      },
      "outputs": [],
      "source": [
        "# Copy YOLOv8l Small Architecture\n",
        "!cp yolov8.yaml yolov8l-small.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuEkTYq5bK0I"
      },
      "source": [
        "#  YOLOv8 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqeZpGvZbRgn"
      },
      "outputs": [],
      "source": [
        "# Training Original Model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"path_model\")\n",
        "results = model.train(\n",
        "    data=\"path_data.yaml\", epochs=250, imgsz=640, device=0, batch=16, workers=2, resume = False, lr0=0.01, lrf=0.001, momentum=0.95,\n",
        "    weight_decay=0.0001, warmup_epochs=10, warmup_momentum=0.5, warmup_bias_lr=0.1, optimizer='SGD', patience=30, plots=True,\n",
        "    name='path_save_dir', hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.>    fliplr=0.1, mosaic=1, mixup=0.2, copy_paste=0.0, cache=False, save=True, save_period=-1, project=None, exist_ok=False, pretrained=True,\n",
        "    verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, amp=True, fraction=1.0, profile=False,\n",
        "    freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split='val', save_json=False, save_hybrid=False,\n",
        "    conf=None, iou=0.7, max_det=300, half=False, dnn=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False,\n",
        "    agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False,\n",
        "    save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format='torchscript', keras=False, optimize=False,\n",
        "    int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0,\n",
        "    label_smoothing=0.0, nbs=64, auto_augment='randaugment', erasing=0.4, crop_fraction=1.0, cfg=None, tracker='botsort.yaml',\n",
        "    save_dir='path_save_dir'\n",
        ")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Resh5LaHb4pJ"
      },
      "source": [
        "# YOLOv8 Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEzDQwpib8lf"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"path_your_model\")\n",
        "\n",
        "# Customize validation settings\n",
        "validation_results = model.val(data=\"path_your_data.yaml\", imgsz=640, batch=16, conf=0.3, iou=0.5, device=\"0\", split = \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AELqj5QTkqTs"
      },
      "source": [
        "#TensorRT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_1C0FOo5qCG",
        "outputId": "e2b60a09-6c7b-4bb5-d7f9-97106d3feb38"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt\n",
        "!pip install tensorrt_lean\n",
        "!pip install tensorrt_dispatch\n",
        "!pip install onnx onnxsim onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EbKETvC5xsx",
        "outputId": "8aea624f-59dc-4b06-af4c-1fe6d75707b5"
      },
      "outputs": [],
      "source": [
        "import tensorrt\n",
        "print(tensorrt.__version__)\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FVjoL4V51Ka",
        "outputId": "e0967184-6b2a-4968-96e4-dcac46bd9df0"
      },
      "outputs": [],
      "source": [
        "!yolo export model=\"path_your_model\"  format=engine half=False device=0 workspace=12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4auBFeVyIudT"
      },
      "source": [
        "## Speed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrf6YivjNRc1",
        "outputId": "6cc3856e-926e-4961-a280-ee6cbab77bc5"
      },
      "outputs": [],
      "source": [
        "# Download modules\n",
        "!gdown https://drive.google.com/uc?id=1RskX1wXVF0xSMAPgpkU-EsaUv8tD7lvS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFRa057JNWNQ",
        "outputId": "9823def5-be00-48b4-97d7-3fa28a2b6559"
      },
      "outputs": [],
      "source": [
        "# Unzip the modules\n",
        "!unzip modules.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T85Kc90LRmjB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def get_name(file_path):\n",
        "  name_idx = 0\n",
        "  file_pos = (file_path).rfind('\\\\')\n",
        "\n",
        "  if(file_pos == -1):\n",
        "      file_pos = (file_path).rfind('/')\n",
        "\n",
        "      if(file_pos == -1):\n",
        "          file_pos = 0\n",
        "\n",
        "  name_idx = file_pos + 1\n",
        "\n",
        "  name = file_path[name_idx:]\n",
        "\n",
        "  return name\n",
        "\n",
        "def get_save_path(file_name, folder_name):\n",
        "  path = \"result\"\n",
        "  save_path = os.path.join(path, folder_name)\n",
        "\n",
        "  exists = os.path.exists(save_path)\n",
        "\n",
        "  if(not exists):\n",
        "      os.makedirs(save_path)\n",
        "\n",
        "  save_path = os.path.join(save_path, file_name)\n",
        "\n",
        "  return save_path\n",
        "\n",
        "def draw_box(img, result, class_list, colors, label_size) :\n",
        "  # Get information from result\n",
        "  xyxy = result.boxes.xyxy.numpy()\n",
        "  confidence = result.boxes.conf.numpy()\n",
        "  class_id = result.boxes.cls.numpy().astype(int)\n",
        "  # Pack together for easy use\n",
        "  sum_output = list(zip(class_id, confidence, xyxy))\n",
        "  # Copy image, in case that we need original image for something\n",
        "  out_image = img.copy()\n",
        "\n",
        "  for run_output in sum_output :\n",
        "    # Unpack\n",
        "    label, con, box = run_output\n",
        "    # Choose color\n",
        "    box_color = colors[int(label)]\n",
        "    text_color = (255,255,255)\n",
        "    # Get Class Name\n",
        "    label = class_list[int(label)]\n",
        "    # Draw object box\n",
        "    first_half_box = (int(box[0]),int(box[1]))\n",
        "    second_half_box = (int(box[2]),int(box[3]))\n",
        "    cv2.rectangle(out_image, first_half_box, second_half_box, box_color, 2)\n",
        "    # Create text\n",
        "    text_print = '{label} {con:.2f}'.format(label = label, con = con)\n",
        "    # Locate text position\n",
        "    text_location = (int(box[0]), int(box[1] - 10 ))\n",
        "    # Get size and baseline\n",
        "    labelSize, baseLine = cv2.getTextSize(text_print, cv2.FONT_HERSHEY_SIMPLEX, label_size, 1)\n",
        "\n",
        "    # Draw text's background\n",
        "    cv2.rectangle(out_image\n",
        "                    , (int(box[0]), int(box[1] - labelSize[1] - 10 ))\n",
        "                    , (int(box[0])+labelSize[0], int(box[1] + baseLine-10))\n",
        "                    , box_color , cv2.FILLED)\n",
        "    # Put text\n",
        "    cv2.putText(out_image, text_print ,text_location\n",
        "                , cv2.FONT_HERSHEY_SIMPLEX , label_size\n",
        "                , text_color, 2, cv2.LINE_AA)\n",
        "\n",
        "  return out_image\n",
        "\n",
        "def draw_fps(avg_fps, combined_img):\n",
        "  avg_fps_str = float(\"{:.2f}\".format(avg_fps))\n",
        "\n",
        "  cv2.rectangle(combined_img, (10,2), (660,110), (255,255,255), -1)\n",
        "  cv2.putText(combined_img, \"FPS: \"+str(avg_fps_str), (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 3.5, (0,255,0), thickness=6)\n",
        "\n",
        "  return combined_img\n",
        "\n",
        "\n",
        "def detection(source, model, folder_name, half=False, label_size=1):\n",
        "  # Initialize video\n",
        "  cap = cv2.VideoCapture(source)\n",
        "\n",
        "  # Initialize YOLOv8 model\n",
        "  model_path = model\n",
        "  yolov8_detector = YOLO(model_path)\n",
        "\n",
        "  # Class Name and Colors\n",
        "  label_map = yolov8_detector.names\n",
        "  COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
        "\n",
        "  # FPS Detection\n",
        "  frame_count = 0\n",
        "  total_fps = 0\n",
        "  avg_fps = 0\n",
        "\n",
        "  # FPS Video\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  frame_width = int(cap.get(3))\n",
        "  frame_height = int(cap.get(4))\n",
        "\n",
        "  video_frames = []\n",
        "\n",
        "  while cap.isOpened():\n",
        "    # Press key q to stop\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        # Read frame from the video\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "\n",
        "    # # Start Time\n",
        "    start = time.time()\n",
        "    # Update object localizer\n",
        "    results = yolov8_detector.predict(frame, half=half, conf=0.5, verbose=False,device=\"0\")\n",
        "    result = results[0].cpu()\n",
        "\n",
        "    # Draw Detection Results\n",
        "    combined_img = draw_box(frame, result, label_map, COLORS, label_size)\n",
        "\n",
        "    end = time.time()\n",
        "    # # End Time\n",
        "\n",
        "    # Draw FPS\n",
        "    frame_count += 1\n",
        "    fps = 1 / (end - start)\n",
        "    total_fps = total_fps + fps\n",
        "    avg_fps = total_fps / frame_count\n",
        "\n",
        "    combined_img = draw_fps(avg_fps, combined_img)\n",
        "\n",
        "    # Append frame to array\n",
        "    video_frames.append(combined_img)\n",
        "\n",
        "    #\n",
        "    print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
        "\n",
        "  print(\"\\nCreate a Video:\")\n",
        "\n",
        "  # Get a file name\n",
        "  file_name = get_name(source)\n",
        "  # Get Save Path\n",
        "  save_path = get_save_path(file_name, folder_name)\n",
        "  # Create VideoWriter object.\n",
        "  out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
        "\n",
        "  for frame in video_frames:\n",
        "    out.write(frame)\n",
        "\n",
        "  out.release()\n",
        "\n",
        "  print(\"Video is saved in: \"+save_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QG9NQueZRokw",
        "outputId": "4d4f507e-7e89-4d52-efae-de518304a49c"
      },
      "outputs": [],
      "source": [
        "detection(\"path_your_video.mp4\", \"path_your_model\", \"path_output_directory\", half=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zAaloLzYVYzb",
        "outputId": "2cb3425d-a169-47be-8d58-68f6aa2cecad"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download( \"path_output_directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ax0jXAHRT6L"
      },
      "source": [
        "## Inference on Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neo_CTTyRlLP",
        "outputId": "debeac4c-38a2-4ac2-dce7-2d2c7469da7f"
      },
      "outputs": [],
      "source": [
        "# Inference Using YOLOv8 Model\n",
        "!yolo detect predict model= \"path_your_model\" source= \"path_your_image\" device=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_du_ZehRWfO"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZam8qEFkzdI"
      },
      "source": [
        "# Supervision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZf7YPXYOHKl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Generator, List\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_zones_config(file_path: str) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Load polygon zone configurations from a JSON file.\n",
        "\n",
        "    This function reads a JSON file which contains polygon coordinates, and\n",
        "    converts them into a list of NumPy arrays. Each polygon is represented as\n",
        "    a NumPy array of coordinates.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON configuration file.\n",
        "\n",
        "    Returns:\n",
        "        List[np.ndarray]: A list of polygons, each represented as a NumPy array.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "        return [np.array(polygon, np.int32) for polygon in data]\n",
        "\n",
        "\n",
        "def find_in_list(array: np.ndarray, search_list: List[int]) -> np.ndarray:\n",
        "    \"\"\"Determines if elements of a numpy array are present in a list.\n",
        "\n",
        "    Args:\n",
        "        array (np.ndarray): The numpy array of integers to check.\n",
        "        search_list (List[int]): The list of integers to search within.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A numpy array of booleans, where each boolean indicates whether\n",
        "        the corresponding element in `array` is found in `search_list`.\n",
        "    \"\"\"\n",
        "    if not search_list:\n",
        "        return np.ones(array.shape, dtype=bool)\n",
        "    else:\n",
        "        return np.isin(array, search_list)\n",
        "\n",
        "\n",
        "def get_stream_frames_generator(rtsp_url: str) -> Generator[np.ndarray, None, None]:\n",
        "    \"\"\"\n",
        "    Generator function to yield frames from an RTSP stream.\n",
        "\n",
        "    Args:\n",
        "        rtsp_url (str): URL of the RTSP video stream.\n",
        "\n",
        "    Yields:\n",
        "        np.ndarray: The next frame from the video stream.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(rtsp_url)\n",
        "    if not cap.isOpened():\n",
        "        raise Exception(\"Error: Could not open video stream.\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"End of stream or error reading frame.\")\n",
        "                break\n",
        "            yield frame\n",
        "    finally:\n",
        "        cap.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEo3fcyFONgu"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "class FPSBasedTimer:\n",
        "    \"\"\"\n",
        "    A timer that calculates the duration each object has been detected based on frames\n",
        "    per second (FPS).\n",
        "\n",
        "    Attributes:\n",
        "        fps (int): The frame rate of the video stream, used to calculate time durations.\n",
        "        frame_id (int): The current frame number in the sequence.\n",
        "        tracker_id2frame_id (Dict[int, int]): Maps each tracker's ID to the frame number\n",
        "            at which it was first detected.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fps: int = 30) -> None:\n",
        "        \"\"\"Initializes the FPSBasedTimer with the specified frames per second rate.\n",
        "\n",
        "        Args:\n",
        "            fps (int, optional): The frame rate of the video stream. Defaults to 30.\n",
        "        \"\"\"\n",
        "        self.fps = fps\n",
        "        self.frame_id = 0\n",
        "        self.tracker_id2frame_id: Dict[int, int] = {}\n",
        "\n",
        "    def tick(self, detections: sv.Detections) -> np.ndarray:\n",
        "        \"\"\"Processes the current frame, updating time durations for each tracker.\n",
        "\n",
        "        Args:\n",
        "            detections: The detections for the current frame, including tracker IDs.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Time durations (in seconds) for each detected tracker, since\n",
        "                their first detection.\n",
        "        \"\"\"\n",
        "        self.frame_id += 1\n",
        "        times = []\n",
        "\n",
        "        for tracker_id in detections.tracker_id:\n",
        "            self.tracker_id2frame_id.setdefault(tracker_id, self.frame_id)\n",
        "\n",
        "            start_frame_id = self.tracker_id2frame_id[tracker_id]\n",
        "            time_duration = (self.frame_id - start_frame_id) / self.fps\n",
        "            times.append(time_duration)\n",
        "\n",
        "        return np.array(times)\n",
        "\n",
        "\n",
        "class ClockBasedTimer:\n",
        "    \"\"\"\n",
        "    A timer that calculates the duration each object has been detected based on the\n",
        "    system clock.\n",
        "\n",
        "    Attributes:\n",
        "        tracker_id2start_time (Dict[int, datetime]): Maps each tracker's ID to the\n",
        "            datetime when it was first detected.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initializes the ClockBasedTimer.\"\"\"\n",
        "        self.tracker_id2start_time: Dict[int, datetime] = {}\n",
        "\n",
        "    def tick(self, detections: sv.Detections) -> np.ndarray:\n",
        "        \"\"\"Processes the current frame, updating time durations for each tracker.\n",
        "\n",
        "        Args:\n",
        "            detections: The detections for the current frame, including tracker IDs.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Time durations (in seconds) for each detected tracker, since\n",
        "                their first detection.\n",
        "        \"\"\"\n",
        "        current_time = datetime.now()\n",
        "        times = []\n",
        "\n",
        "        for tracker_id in detections.tracker_id:\n",
        "            self.tracker_id2start_time.setdefault(tracker_id, current_time)\n",
        "\n",
        "            start_time = self.tracker_id2start_time[tracker_id]\n",
        "            time_duration = (current_time - start_time).total_seconds()\n",
        "            times.append(time_duration)\n",
        "\n",
        "        return np.array(times)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJKJjfNdg9CJ",
        "outputId": "bcc9b7fa-557d-4ba3-a8aa-5063e066c461"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from typing import List\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "COLORS = sv.ColorPalette.from_hex([\"#E6194B\", \"#3CB44B\", \"#FFE119\", \"#3C76D1\"])\n",
        "COLOR_ANNOTATOR = sv.ColorAnnotator(color=COLORS)\n",
        "LABEL_ANNOTATOR = sv.LabelAnnotator(\n",
        "    color=COLORS, text_color=sv.Color.from_hex(\"#000000\")\n",
        ")\n",
        "\n",
        "source_video_path = \"path_your_video\"\n",
        "zone_configuration_path = \"/content/data/config.json\"\n",
        "output_video_path = \"path_output_directory\"\n",
        "weights = \"path_your_model\"\n",
        "device = \"cuda\"\n",
        "confidence = 0.3\n",
        "iou = 0.7\n",
        "classes = 0\n",
        "\n",
        "model = YOLO(weights,task = \"detect\")\n",
        "tracker = sv.ByteTrack(minimum_matching_threshold=0.5)\n",
        "video_info = sv.VideoInfo.from_video_path(video_path=source_video_path)\n",
        "frames_generator = sv.get_video_frames_generator(source_video_path)\n",
        "\n",
        "polygons = load_zones_config(file_path=zone_configuration_path)\n",
        "zones = [\n",
        "    sv.PolygonZone(\n",
        "        polygon=polygon,\n",
        "        triggering_anchors=(sv.Position.CENTER,),\n",
        "    )\n",
        "    for polygon in polygons\n",
        "]\n",
        "timers = [FPSBasedTimer(video_info.fps) for _ in zones]\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, video_info.fps, (video_info.width, video_info.height))\n",
        "\n",
        "for frame in frames_generator:\n",
        "    results = model(frame, verbose=False, device=device, conf=confidence)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    detections = detections[find_in_list(detections.class_id, classes)]\n",
        "    detections = detections.with_nms(threshold=iou)\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    for idx, zone in enumerate(zones):\n",
        "        annotated_frame = sv.draw_polygon(\n",
        "            scene=annotated_frame, polygon=zone.polygon, color=COLORS.by_idx(idx)\n",
        "        )\n",
        "\n",
        "        detections_in_zone = detections[zone.trigger(detections)]\n",
        "        time_in_zone = timers[idx].tick(detections_in_zone)\n",
        "        custom_color_lookup = np.full(detections_in_zone.class_id.shape, idx)\n",
        "\n",
        "        annotated_frame = COLOR_ANNOTATOR.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=detections_in_zone,\n",
        "            custom_color_lookup=custom_color_lookup,\n",
        "        )\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {int(time // 60):02d}:{int(time % 60):02d}\"\n",
        "            for tracker_id, time in zip(detections_in_zone.tracker_id, time_in_zone)\n",
        "        ]\n",
        "        annotated_frame = LABEL_ANNOTATOR.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=detections_in_zone,\n",
        "            labels=labels,\n",
        "            custom_color_lookup=custom_color_lookup,\n",
        "        )\n",
        "\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h1Jc5Mb4TsPn",
        "outputId": "96b01e60-e5dd-4c7d-8d99-cce2a85df23e"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"path_your_video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ccZeQIay6H"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VAzz_fL1a0wS",
        "AuEkTYq5bK0I",
        "Resh5LaHb4pJ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
